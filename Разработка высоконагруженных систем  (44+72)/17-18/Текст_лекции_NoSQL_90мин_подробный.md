# Текст лекции: NoSQL - MongoDB и OpenSearch (90 минут)
## Для лектора-программиста

---

## Введение (5 минут)

Всем привет! Сегодня у нас тема, которая реально пригодится в работе - NoSQL базы данных. Конкретно разберем MongoDB и OpenSearch. 

**Слайд 1: Титульный**

Короче, ребят, сегодня будем говорить про NoSQL. Не пугайтесь, это не значит "нет SQL" - это "Not Only SQL". То есть не только реляционные базы, но и другие подходы к хранению данных.

Мы разберем две популярные NoSQL базы:
- **MongoDB** - для хранения JSON-документов
- **OpenSearch** - для полнотекстового поиска

И самое главное - как с ними работать через Python и FastAPI. Все будет с примерами кода, которые можно сразу юзать в проектах.

---

## Часть 1: Введение в NoSQL (10 минут)

**Слайд 2: Проблемы реляционных БД**

Окей, давайте сначала разберемся, а зачем вообще эти NoSQL базы придумали? PostgreSQL же норм работает, MySQL тоже ничего. В чем проблема?

Проблемы начинаются, когда проект растет:

### 1. Вертикальное масштабирование - это боль

Представьте: у вас PostgreSQL на сервере с 16GB RAM. Все хорошо. Потом пользователей стало больше, данных больше - база тормозит. Что делать? 

Покупать сервер с 32GB RAM. Потом с 64GB. Потом с 128GB. Это называется **вертикальное масштабирование** - апгрейдим железо.

Проблемы:
- **Дорого** - сервер с 256GB RAM стоит как подержанная машина
- **Есть предел** - больше определенного размера сервер не сделаешь
- **Single point of failure** - если сервер упал, все упало

### 2. Жёсткая схема - это головная боль

В реляционных БД нужно заранее создать таблицы:

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(100)
);
```

А потом приходит менеджер: "Слушай, а давай еще поле `phone` добавим". Окей:

```sql
ALTER TABLE users ADD COLUMN phone VARCHAR(20);
```

Потом: "А давай еще `address` добавим, но он должен быть JSON с городом, улицей, домом...". И начинается:

```sql
ALTER TABLE users ADD COLUMN address JSONB;
```

А потом оказывается, что у половины пользователей адреса нет, у четверти он в старом формате, у остальных - в новом. И ты сидишь пишешь миграции, которые это все чинят.

В NoSQL базах **схема гибкая** - можно в одной коллекции хранить документы с разной структурой. Добавил поле - и все, никаких миграций.

### 3. Иерархические данные - это ад

Попробуйте в реляционной БД хранить такую структуру:

```json
{
  "user": "Иван",
  "orders": [
    {
      "id": 1,
      "items": [
        {"product": "Ноутбук", "price": 50000},
        {"product": "Мышка", "price": 1000}
      ]
    }
  ]
}
```

Вам нужно создать 3 таблицы: `users`, `orders`, `order_items`. Потом делать JOIN'ы:

```sql
SELECT u.name, o.id, oi.product, oi.price
FROM users u
JOIN orders o ON u.id = o.user_id
JOIN order_items oi ON o.id = oi.order_id
WHERE u.name = 'Иван';
```

А в MongoDB это просто один документ. Запросил - получил. Все.

### 4. Производительность при больших объёмах

Когда в таблице миллионы строк и нужно делать JOIN по нескольким таблицам - PostgreSQL начинает думать. Долго думать. Индексы помогают, но не всегда.

**Слайд 3: Что такое NoSQL?**

NoSQL = **Not Only SQL**. Это не замена реляционным БД, а дополнение.

Основные фишки:

### 1. Горизонтальное масштабирование

Вместо одного мощного сервера - куча обычных серверов. Данные распределяются между ними автоматически.

Пример: у вас 3 сервера по 16GB RAM. MongoDB автоматически распределит данные между ними. Нужно больше мощности? Добавляете 4-й сервер - MongoDB сам перебалансирует данные.

Это называется **шардинг** (sharding). Данные разбиваются на куски (шарды) и раскидываются по серверам.

### 2. Гибкая схема

Можно хранить документы с разной структурой в одной коллекции:

```javascript
// Документ 1
{
  "name": "Иван",
  "age": 25
}

// Документ 2
{
  "name": "Мария",
  "age": 30,
  "city": "Москва",  // Новое поле!
  "hobbies": ["программирование", "бег"]  // Еще одно!
}
```

MongoDB скажет: "Норм, принял". PostgreSQL скажет: "ERROR: column 'city' does not exist".

### 3. CAP-теорема

Это важная штука. CAP = Consistency, Availability, Partition tolerance.

Простыми словами:
- **Consistency** (консистентность) - все видят одинаковые данные
- **Availability** (доступность) - система всегда отвечает
- **Partition tolerance** (устойчивость к разделению) - система работает, даже если связь между серверами пропала

Теорема говорит: **можно выбрать только 2 из 3**.

Реляционные БД выбирают **CA** (консистентность + доступность). Если связь между серверами пропала - система падает.

NoSQL базы обычно выбирают **AP** (доступность + устойчивость). Если связь пропала - система работает, но данные могут быть не синхронизированы. Потом синхронизируются.

**Слайд 4: Типы NoSQL-СУБД**

NoSQL - это не одна технология, а целое семейство. Разберем основные типы:

### 1. Document Store (MongoDB, Couchbase)

Хранят JSON-подобные документы. Это самый популярный тип.

**Когда юзать**: 
- Каталог товаров (у каждого товара свои характеристики)
- Профили пользователей
- CMS (системы управления контентом)

### 2. Key-Value (Redis, Memcached)

Простейшая структура: ключ → значение. Как Python словарь, но в базе данных.

```python
cache["user:123"] = {"name": "Иван", "age": 25}
```

**Когда юзать**:
- Кеширование
- Сессии пользователей
- Очереди задач

### 3. Column Family (Cassandra, HBase)

Данные хранятся по колонкам, а не по строкам. Звучит странно, но для аналитики это быстрее.

**Когда юзать**:
- Аналитика больших данных
- Временные ряды (метрики, логи)

### 4. Graph (Neo4j, ArangoDB)

Для связанных данных. Хранит узлы (nodes) и связи (edges).

**Когда юзать**:
- Социальные сети (друзья, подписчики)
- Рекомендательные системы
- Графы знаний

### 5. Search Engine (Elasticsearch, OpenSearch)

Для полнотекстового поиска. Умеет искать по словам, с опечатками, с морфологией.

**Когда юзать**:
- Поиск по сайту
- Логирование (ELK stack)
- Аналитика в реальном времени

Сегодня мы подробно разберем **Document Store (MongoDB)** и **Search Engine (OpenSearch)**.

**Слайд 5: Когда использовать NoSQL?**

NoSQL подходит когда:

### 1. Большие объёмы неструктурированных данных

Логи, JSON от API, данные с датчиков IoT - все это неструктурированные данные. В реляционной БД их хранить неудобно.

### 2. Высокая скорость записи

Нужно писать миллионы событий в секунду? MongoDB справится. PostgreSQL - нет.

### 3. Схема данных часто меняется

Стартапы, прототипы - требования меняются каждую неделю. Гибкая схема MongoDB спасает.

### 4. Полнотекстовый поиск

Нужен поиск по тексту с морфологией, опечатками, ранжированием? OpenSearch/Elasticsearch - ваш выбор.

### 5. Аналитика в реальном времени

Нужно считать статистику на лету? OpenSearch умеет агрегации за миллисекунды.

---

## Часть 2: MongoDB (35 минут)

**Слайд 6: MongoDB**

MongoDB - это самая популярная NoSQL база данных. Название от "humongous" (огромный).

Основные фишки:

### 1. BSON формат

Данные хранятся в формате BSON (Binary JSON). Это JSON, но:
- Бинарный (быстрее парсится)
- Поддерживает дополнительные типы (Date, ObjectId, Binary)
- Компактнее

### 2. Гибкая схема

Можно хранить документы с разной структурой. Никаких миграций.

### 3. Шардинг из коробки

MongoDB сам распределяет данные по серверам. Настроил - и работает.

**Слайд 7: Архитектура MongoDB**

Давайте разберем, как MongoDB устроена внутри.

### Уровень приложения

Ваше приложение на Python, Node.js, Java - подключается к MongoDB через драйвер. Драйвер - это библиотека, которая умеет говорить с MongoDB по сети.

### MongoDB Server (mongod)

Это процесс, который крутится на сервере. Он:
- Принимает запросы от приложений
- Читает/пишет данные
- Управляет индексами
- Делает репликацию

### Query Router (mongos)

Если у вас кластер с шардингом, между приложением и серверами стоит роутер. Он:
- Принимает запрос от приложения
- Определяет, на каком сервере лежат нужные данные
- Отправляет запрос на нужный сервер
- Собирает результаты и отдает приложению

### Storage Engine

Это движок, который физически пишет данные на диск. По умолчанию используется **WiredTiger**:
- Сжимает данные (экономит место)
- Поддерживает транзакции
- Делает снапшоты для бэкапов

Есть также **In-Memory** движок - все данные в RAM, максимальная скорость. Но если сервер упал - данные потеряны.

**Слайд 8: Основные концепции**

В MongoDB иерархия такая:

```
Database (БД)
  └─ Collection (Коллекция)
       └─ Document (Документ)
            └─ Field (Поле)
```

Аналогия с реляционными БД:
- **Database** ≈ Database
- **Collection** ≈ Table
- **Document** ≈ Row
- **Field** ≈ Column

Но есть важное отличие: **документ - это JSON-объект**, а не строка в таблице.

### Поле _id

Каждый документ имеет поле `_id` - уникальный идентификатор. Если вы его не укажете, MongoDB создаст автоматически.

```javascript
{
  "_id": ObjectId("507f1f77bcf86cd799439011"),
  "name": "Иван",
  "age": 25
}
```

`ObjectId` - это специальный тип, 12-байтовое значение:
- 4 байта - timestamp (когда создан)
- 5 байт - случайное значение (machine ID + process ID)
- 3 байта - счетчик

Благодаря этому `ObjectId` уникален даже в распределенной системе без координации между серверами.

**Слайд 9: Системные БД**

В MongoDB есть 3 системные базы данных, которые создаются автоматически:

### 1. admin

Это главная административная база. Здесь хранятся:
- Пользователи и их права
- Роли (roles)
- Команды управления кластером

Если создать пользователя в `admin` с ролью `root` - он будет иметь доступ ко всем базам.

### 2. config

Используется только при **шардинге** (распределении данных по серверам). Хранит:
- Метаданные о шардах (какие сервера в кластере)
- Информацию о том, какие данные на каком сервере лежат
- Настройки балансировки

Если у вас один сервер - эта база пустая.

### 3. local

Локальная база, которая **не реплицируется** между серверами. Хранит:
- **oplog** (operation log) - журнал всех операций для репликации
- Временные данные
- Startup log

⚠️ **Важно**: Эти базы создаются автоматически. Не удаляйте их и не пишите туда свои данные!

---

**Слайд 10: Установка MongoDB**

Окей, теория - это хорошо, но давайте уже запустим MongoDB и попробуем с ней поработать.

Самый простой способ - через Docker:

```bash
# Официальный образ MongoDB 7
docker run -d -p 27017:27017 mongo:7
```

Что здесь происходит:
- `-d` - запуск в фоновом режиме (detached)
- `-p 27017:27017` - пробрасываем порт 27017 (стандартный порт MongoDB)
- `mongo:7` - образ MongoDB версии 7

### Альтернатива для РФ - Percona Server

Если у вас проблемы с доступом к Docker Hub, можно использовать **Percona Server for MongoDB** - это форк MongoDB с открытым исходным кодом:

```bash
docker run -d -p 27017:27017 percona/percona-server-mongodb:7.0
```

Percona полностью совместима с MongoDB, но:
- Бесплатная и открытая
- Есть дополнительные фичи (шифрование, аудит)
- Активно поддерживается

После запуска MongoDB доступна по адресу `mongodb://localhost:27017`.

---

**Слайд 11: Подключение Python**

Для работы с MongoDB из Python используем библиотеку **Motor** - это асинхронный драйвер.

Установка:

```bash
pip install motor
```

Подключение:

```python
from motor.motor_asyncio import AsyncIOMotorClient

# Подключение к MongoDB
client = AsyncIOMotorClient("mongodb://localhost:27017")

# Выбор базы данных
db = client["university_db"]  # Или client.university_db

# Выбор коллекции
collection = db["students"]  # Или db.students
```

Важные моменты:
- База и коллекция создаются **автоматически** при первой записи
- Не нужно делать `CREATE DATABASE` или `CREATE TABLE`
- Все операции асинхронные - используем `await`

Если нужен синхронный драйвер (без async/await):

```python
from pymongo import MongoClient

client = MongoClient("mongodb://localhost:27017")
db = client.university_db
collection = db.students
```

Но в FastAPI лучше использовать асинхронный Motor - он не блокирует event loop.

---

## Часть 3: CRUD операции в MongoDB (15 минут)

**Слайд 12: CRUD - Create**

Давайте начнем с создания документов. В MongoDB это называется **insert**.

### Вставка одного документа

```python
# Создаем документ (обычный Python словарь)
student = {
    "name": "Иван Иванов",
    "age": 21,
    "courses": ["Математика", "Программирование"],
    "address": {
        "city": "Москва",
        "street": "Ленина"
    }
}

# Вставка одного документа
result = await collection.insert_one(student)

# Получаем ID вставленного документа
print(result.inserted_id)  # ObjectId('...')
```

МongoDB автоматически добавит поле `_id` с уникальным `ObjectId`.

### Вставка нескольких документов

```python
students = [
    {"name": "Мария Петрова", "age": 22},
    {"name": "Петр Сидоров", "age": 20},
    {"name": "Анна Смирнова", "age": 21}
]

result = await collection.insert_many(students)

# Список ID вставленных документов
print(result.inserted_ids)  # [ObjectId('...'), ObjectId('...'), ...]
```

Обратите внимание: документы могут иметь **разную структуру**. У первого студента есть `courses` и `address`, у остальных - нет. MongoDB это нормально воспринимает.

**Слайд 13: CRUD - Read**

Теперь научимся читать данные из MongoDB.

### Найти один документ

```python
# Найти первый документ с именем "Иван"
student = await collection.find_one({"name": "Иван Иванов"})

print(student)
# {
#   "_id": ObjectId('...'),
#   "name": "Иван Иванов",
#   "age": 21,
#   "courses": [...]
# }
```

Если документ не найден - вернется `None`.

### Найти несколько документов

```python
# Найти всех студентов старше 20 лет
cursor = collection.find({"age": {"$gte": 20}})

# Преобразуем курсор в список
students = await cursor.to_list(length=100)  # Максимум 100 документов

# Или итерируемся по курсору
async for student in collection.find({"age": {"$gte": 20}}):
    print(student["name"])
```

`find()` возвращает **курсор** - это ленивый итератор. Данные загружаются по мере необходимости.

### Проекция (выбор полей)

Часто не нужны все поля документа. Можно выбрать только нужные:

```python
# Вернуть только name и age, без _id
cursor = collection.find(
    {},  # Пустой фильтр = все документы
    {"name": 1, "age": 1, "_id": 0}  # 1 = включить, 0 = исключить
)

students = await cursor.to_list(length=100)
# [{"name": "Иван", "age": 21}, {"name": "Мария", "age": 22}, ...]
```

Правила проекции:
- `1` - включить поле
- `0` - исключить поле
- Нельзя смешивать включение и исключение (кроме `_id`)
- `_id` включается по умолчанию, нужно явно исключить

**Слайд 14: CRUD - Update**

Обновление документов в MongoDB.

### Обновить один документ

```python
# Обновить возраст Ивана на 22
await collection.update_one(
    {"name": "Иван Иванов"},  # Фильтр (какой документ обновить)
    {"$set": {"age": 22}}  # Операция обновления
)
```

Оператор `$set` устанавливает значение поля. Если поля нет - оно создается.

### Обновить несколько документов

```python
# Увеличить возраст всех студентов младше 20 лет на 1
await collection.update_many(
    {"age": {"$lt": 20}},  # Фильтр
    {"$inc": {"age": 1}}  # $inc - увеличить на N
)
```

### Операторы обновления

```python
# $set - установить значение
{"$set": {"age": 25}}

# $inc - увеличить/уменьшить
{"$inc": {"age": 1}}  # +1
{"$inc": {"age": -1}}  # -1

# $unset - удалить поле
{"$unset": {"address": ""}}

# $rename - переименовать поле
{"$rename": {"name": "full_name"}}

# $currentDate - установить текущую дату
{"$currentDate": {"updated_at": True}}
```

### Upsert (update or insert)

```python
# Если документ найден - обновить, если нет - создать
await collection.update_one(
    {"name": "Новый студент"},
    {"$set": {"age": 20}},
    upsert=True  # Магия здесь
)
```

**Слайд 15: CRUD - Delete**

Удаление документов.

### Удалить один документ

```python
# Удалить первый документ с именем "Иван"
result = await collection.delete_one({"name": "Иван Иванов"})

print(result.deleted_count)  # Количество удаленных документов (0 или 1)
```

### Удалить несколько документов

```python
# Удалить всех студентов младше 18 лет
result = await collection.delete_many({"age": {"$lt": 18}})

print(result.deleted_count)  # Количество удаленных документов
```

### Удалить все документы

```python
# Удалить ВСЕ документы из коллекции
await collection.delete_many({})  # Пустой фильтр = все документы

# Или удалить саму коллекцию
await collection.drop()
```

⚠️ **Осторожно**: `delete_many({})` удаляет все данные без подтверждения!

---

**Слайд 16: Операторы запросов**

MongoDB имеет богатый язык запросов. Разберем основные операторы.

### Операторы сравнения

```python
# $gt - больше (greater than)
{"age": {"$gt": 20}}  # age > 20

# $gte - больше или равно
{"age": {"$gte": 20}}  # age >= 20

# $lt - меньше (less than)
{"age": {"$lt": 25}}  # age < 25

# $lte - меньше или равно
{"age": {"$lte": 25}}  # age <= 25

# $eq - равно (можно не писать)
{"age": {"$eq": 20}}  # age == 20
{"age": 20}  # То же самое

# $ne - не равно
{"age": {"$ne": 20}}  # age != 20
```

### Логические операторы

```python
# $and - И (можно не писать, по умолчанию)
{"$and": [
    {"age": {"$gte": 20}},
    {"age": {"$lte": 25}}
]}
# Или короче:
{"age": {"$gte": 20, "$lte": 25}}  # 20 <= age <= 25

# $or - ИЛИ
{"$or": [
    {"name": "Иван"},
    {"name": "Петр"}
]}

# $not - НЕ
{"age": {"$not": {"$gte": 20}}}  # НЕ (age >= 20) = age < 20

# $nor - НИ ... НИ
{"$nor": [
    {"age": {"$lt": 18}},
    {"age": {"$gt": 65}}
]}  # Не младше 18 и не старше 65
```

### Операторы массивов

```python
# $in - значение в списке
{"age": {"$in": [20, 21, 22]}}  # age IN (20, 21, 22)

# $nin - значение НЕ в списке
{"age": {"$nin": [20, 21, 22]}}

# $exists - поле существует
{"address": {"$exists": True}}  # Есть поле address
{"address": {"$exists": False}}  # Нет поля address

# $type - тип поля
{"age": {"$type": "int"}}  # age - целое число
{"age": {"$type": "string"}}  # age - строка
```

**Слайд 17: Работа с массивами**

MongoDB отлично работает с массивами внутри документов.

### Поиск в массивах

```python
# Найти студентов, у которых есть курс "Математика"
{"courses": "Математика"}

# Найти студентов, у которых есть ВСЕ указанные курсы
{"courses": {"$all": ["Математика", "Физика"]}}

# Найти студентов, у которых больше 2 курсов
{"courses": {"$size": 3}}  # Ровно 3 курса

# Найти студентов с любым из курсов
{"courses": {"$in": ["Математика", "Физика"]}}
```

### Обновление массивов

```python
# $push - добавить элемент в конец массива
await collection.update_one(
    {"name": "Иван"},
    {"$push": {"courses": "Новый курс"}}
)

# $pull - удалить элемент из массива
await collection.update_one(
    {"name": "Иван"},
    {"$pull": {"courses": "Старый курс"}}
)

# $addToSet - добавить, если еще нет (уникальность)
await collection.update_one(
    {"name": "Иван"},
    {"$addToSet": {"courses": "Уникальный курс"}}
)

# $pop - удалить первый или последний элемент
await collection.update_one(
    {"name": "Иван"},
    {"$pop": {"courses": 1}}  # 1 = последний, -1 = первый
)
```

### Фильтрация элементов массива

```python
# $elemMatch - найти документ, где элемент массива соответствует условиям
collection.find({
    "grades": {
        "$elemMatch": {
            "subject": "Математика",
            "score": {"$gte": 80}
        }
    }
})
# Найдет студентов, у которых по математике >= 80 баллов
```

---

## Часть 4: Агрегация в MongoDB (10 минут)
- 5 байт - случайное значение
- 3 байта - счетчик

Благодаря этому `ObjectId` уникален даже в распределенной системе.

### Индексы

Индексы работают так же, как в реляционных БД - ускоряют поиск. Без индекса MongoDB сканирует всю коллекцию (collection scan). С индексом - только нужные документы.

**Слайд 9: Системные БД**

MongoDB создает 3 системные базы данных автоматически. Не трогайте их!

### 1. admin

Тут хранятся:
- Пользователи и их права
- Роли
- Административные команды

Если удалите - не сможете подключиться к MongoDB.

### 2. config

Используется только при шардинге. Хранит:
- Метаданные о шардах (какие серверы, какие данные где лежат)
- Настройки балансировки

### 3. local

Не реплицируется между серверами. Хранит:
- **oplog** (operation log) - лог всех операций для репликации
- Временные данные
- Startup log

**Слайд 10: Установка MongoDB**

Для разработки проще всего юзать Docker. Одна команда - и MongoDB крутится:

```bash
docker run -d -p 27017:27017 mongo:7
```

Что тут происходит:
- `-d` - запуск в фоне (detached)
- `-p 27017:27017` - пробрасываем порт (27017 - дефолтный порт MongoDB)
- `mongo:7` - образ MongoDB версии 7

### Для России - Percona

Если боитесь санкций, юзайте Percona Server for MongoDB. Это полностью совместимый форк:

```bash
docker run -d -p 27017:27017 percona/percona-server-mongodb:7.0
```

Работает точно так же, но разрабатывается Percona (американская компания, но open-source).

**Слайд 11: Подключение Python**

Для работы с MongoDB из Python юзаем библиотеку **Motor** - это асинхронный драйвер.

```python
from motor.motor_asyncio import AsyncIOMotorClient

# Подключаемся к MongoDB
client = AsyncIOMotorClient("mongodb://localhost:27017")

# Выбираем БД (если не существует - создастся автоматически)
db = client["university_db"]

# Выбираем коллекцию (тоже создастся автоматически)
collection = db["students"]
```

Почему Motor, а не PyMongo? Потому что Motor работает с `async/await`, а PyMongo - синхронный. Для FastAPI нужен асинхронный драйвер.

**Слайды 12-15: CRUD операции**

Теперь самое важное - как работать с данными. CRUD = Create, Read, Update, Delete.

### CREATE - создание документов

```python
# Создаем документ (обычный Python словарь)
student = {
    "name": "Иван Иванов",
    "age": 21,
    "courses": ["Математика", "Программирование"],
    "grades": {"Математика": 5, "Программирование": 4}
}

# Вставляем один документ
result = await collection.insert_one(student)
print(f"Вставлен документ с ID: {result.inserted_id}")

# Вставляем несколько документов
students = [
    {"name": "Мария", "age": 20},
    {"name": "Петр", "age": 22}
]
result = await collection.insert_many(students)
print(f"Вставлено {len(result.inserted_ids)} документов")
```

Обратите внимание: мы просто передаем Python словарь. Никаких схем, никаких миграций. Просто взяли и вставили.

### READ - чтение документов

```python
# Найти один документ
student = await collection.find_one({"name": "Иван"})
print(student)  # {'_id': ObjectId(...), 'name': 'Иван', 'age': 21, ...}

# Найти все документы с условием
cursor = collection.find({"age": {"$gte": 20}})  # age >= 20
students = await cursor.to_list(length=100)  # Получить до 100 документов

# Проекция - выбрать только нужные поля
cursor = collection.find(
    {},  # Пустой фильтр = все документы
    {"name": 1, "age": 1, "_id": 0}  # 1 = включить, 0 = исключить
)
students = await cursor.to_list(length=100)
# Результат: [{'name': 'Иван', 'age': 21}, ...]
```

`$gte` - это оператор "больше или равно". Таких операторов куча, разберем дальше.

### UPDATE - обновление документов

```python
# Обновить один документ
result = await collection.update_one(
    {"name": "Иван"},  # Фильтр - что обновляем
    {"$set": {"age": 22}}  # $set - установить значение
)
print(f"Обновлено документов: {result.modified_count}")

# Обновить несколько документов
result = await collection.update_many(
    {"age": {"$lt": 20}},  # age < 20
    {"$inc": {"age": 1}}  # $inc - увеличить на 1
)
print(f"Обновлено документов: {result.modified_count}")

# Добавить элемент в массив
await collection.update_one(
    {"name": "Иван"},
    {"$push": {"courses": "Физика"}}  # Добавить "Физика" в массив courses
)
```

Операторы обновления:
- `$set` - установить значение
- `$inc` - увеличить/уменьшить число
- `$push` - добавить в массив
- `$pull` - удалить из массива
- `$unset` - удалить поле

### DELETE - удаление документов

```python
# Удалить один документ
result = await collection.delete_one({"name": "Иван"})
print(f"Удалено документов: {result.deleted_count}")

# Удалить несколько документов
result = await collection.delete_many({"age": {"$lt": 18}})  # age < 18
print(f"Удалено документов: {result.deleted_count}")

# Удалить все документы в коллекции (осторожно!)
result = await collection.delete_many({})
```

**Слайд 16: Операторы запросов**

MongoDB имеет богатый язык запросов. Разберем основные операторы:

### Операторы сравнения

```python
# Больше
{"age": {"$gt": 20}}  # age > 20

# Больше или равно
{"age": {"$gte": 20}}  # age >= 20

# Меньше
{"age": {"$lt": 25}}  # age < 25

# Меньше или равно
{"age": {"$lte": 25}}  # age <= 25

# Не равно
{"age": {"$ne": 20}}  # age != 20

# В списке
{"age": {"$in": [20, 21, 22]}}  # age IN (20, 21, 22)

# Не в списке
{"age": {"$nin": [18, 19]}}  # age NOT IN (18, 19)
```

### Логические операторы

```python
# AND (все условия должны выполняться)
{
    "$and": [
        {"age": {"$gte": 20}},
        {"age": {"$lte": 25}}
    ]
}
# Можно короче:
{"age": {"$gte": 20, "$lte": 25}}  # 20 <= age <= 25

# OR (хотя бы одно условие)
{
    "$or": [
        {"name": "Иван"},
        {"name": "Петр"}
    ]
}

# NOT (отрицание)
{"age": {"$not": {"$gte": 20}}}  # НЕ (age >= 20) = age < 20
```

### Проверка существования поля

```python
# Поле существует
{"email": {"$exists": True}}

# Поля нет
{"email": {"$exists": False}}
```

**Слайд 17: Работа с массивами**

MongoDB отлично работает с массивами. Это одна из его сильных сторон.

### Поиск в массивах

```python
# Найти студентов, изучающих математику
{"courses": "Математика"}  # Ищет "Математика" в массиве courses

# Найти тех, кто изучает И математику, И физику
{"courses": {"$all": ["Математика", "Физика"]}}

# Найти тех, кто изучает математику ИЛИ физику
{"courses": {"$in": ["Математика", "Физика"]}}

# Массив содержит хотя бы 3 элемента
{"courses": {"$size": 3}}

# Массив содержит больше 2 элементов (через $expr)
{"$expr": {"$gt": [{"$size": "$courses"}, 2]}}
```

### Обновление массивов

```python
# Добавить элемент в конец массива
{"$push": {"courses": "Физика"}}

# Добавить несколько элементов
{"$push": {"courses": {"$each": ["Физика", "Химия"]}}}

# Добавить только если нет (уникальность)
{"$addToSet": {"courses": "Физика"}}

# Удалить элемент
{"$pull": {"courses": "Физика"}}

# Удалить несколько элементов
{"$pull": {"courses": {"$in": ["Физика", "Химия"]}}}

# Удалить первый элемент
{"$pop": {"courses": -1}}  # -1 = первый, 1 = последний
```

**Продолжение следует...**


**Слайд 18: Агрегация - Концепция**

Агрегация в MongoDB - это мощный инструмент для обработки данных. Работает как конвейер (pipeline) - данные проходят через несколько стадий обработки.

Представьте конвейер на заводе: сырье → обработка → фильтрация → упаковка → готовый продукт.

В MongoDB так же: документы → фильтр → группировка → сортировка → результат.

### Пример агрегации

```python
pipeline = [
    # Стадия 1: Фильтрация (аналог WHERE в SQL)
    {"$match": {"age": {"$gte": 20}}},
    
    # Стадия 2: Группировка (аналог GROUP BY)
    {"$group": {
        "_id": "$course",  # Группировать по полю course
        "avg_grade": {"$avg": "$grade"},  # Средний балл
        "count": {"$sum": 1}  # Подсчет количества
    }},
    
    # Стадия 3: Сортировка (аналог ORDER BY)
    {"$sort": {"avg_grade": -1}},  # -1 = по убыванию, 1 = по возрастанию
    
    # Стадия 4: Ограничение (аналог LIMIT)
    {"$limit": 10}
]

results = await collection.aggregate(pipeline).to_list(None)
```

Это эквивалентно SQL:

```sql
SELECT course, AVG(grade) as avg_grade, COUNT(*) as count
FROM students
WHERE age >= 20
GROUP BY course
ORDER BY avg_grade DESC
LIMIT 10
```

**Слайд 19: Агрегация - Стадии**

Разберем основные стадии агрегации подробнее.

### Базовые стадии

**$match** - фильтрация документов (аналог WHERE)

```python
{"$match": {"age": {"$gte": 20}}}  # Только студенты >= 20 лет
```

Важно: `$match` лучше ставить в начало pipeline - так MongoDB использует индексы и обрабатывает меньше данных.

**$group** - группировка по полю (аналог GROUP BY)

```python
{"$group": {
    "_id": "$city",  # Группировать по городу
    "total": {"$sum": 1},  # Подсчет
    "avg_age": {"$avg": "$age"}  # Средний возраст
}}
```

**$sort** - сортировка результатов

```python
{"$sort": {"age": 1}}  # 1 = по возрастанию
{"$sort": {"age": -1}}  # -1 = по убыванию
{"$sort": {"age": -1, "name": 1}}  # Сначала по age, потом по name
```

**$limit** - ограничение количества

```python
{"$limit": 10}  # Вернуть только 10 документов
```

**$skip** - пропустить N документов

```python
{"$skip": 20}  # Пропустить первые 20 документов
```

**$project** - выбор полей (аналог SELECT)

```python
{"$project": {
    "name": 1,  # Включить поле name
    "age": 1,  # Включить поле age
    "_id": 0,  # Исключить _id
    "age_in_months": {"$multiply": ["$age", 12]}  # Вычисляемое поле
}}
```

### Продвинутые стадии

**$lookup** - объединение коллекций (аналог JOIN)

```python
{"$lookup": {
    "from": "courses",  # Коллекция для объединения
    "localField": "course_id",  # Поле в текущей коллекции
    "foreignField": "_id",  # Поле в courses
    "as": "course_info"  # Имя нового поля с результатом
}}
```

**$unwind** - разворачивание массивов

Если у документа есть массив, `$unwind` создает отдельный документ для каждого элемента массива.

```python
# До $unwind:
{"name": "Иван", "courses": ["Математика", "Физика"]}

# После $unwind:
{"name": "Иван", "courses": "Математика"}
{"name": "Иван", "courses": "Физика"}

# Код:
{"$unwind": "$courses"}
```

**$addFields** - добавление вычисляемых полей

```python
{"$addFields": {
    "full_name": {"$concat": ["$first_name", " ", "$last_name"]},
    "age_category": {
        "$cond": {
            "if": {"$gte": ["$age", 18]},
            "then": "adult",
            "else": "minor"
        }
    }
}}
```

### Операторы агрегации

**Математические:**
- `$sum` - сумма
- `$avg` - среднее
- `$min` - минимум
- `$max` - максимум
- `$multiply`, `$divide`, `$add`, `$subtract` - арифметика

**Для массивов:**
- `$push` - собрать значения в массив
- `$addToSet` - собрать уникальные значения
- `$first` - первый элемент группы
- `$last` - последний элемент группы

**Пример сложной агрегации:**

```python
pipeline = [
    # 1. Фильтруем активных студентов
    {"$match": {"status": "active"}},
    
    # 2. Разворачиваем массив курсов
    {"$unwind": "$courses"},
    
    # 3. Группируем по курсу
    {"$group": {
        "_id": "$courses",
        "students": {"$push": "$name"},  # Массив имен
        "count": {"$sum": 1},
        "avg_age": {"$avg": "$age"}
    }},
    
    # 4. Фильтруем курсы с > 5 студентами
    {"$match": {"count": {"$gt": 5}}},
    
    # 5. Сортируем по количеству
    {"$sort": {"count": -1}},
    
    # 6. Топ-10 курсов
    {"$limit": 10}
]

results = await collection.aggregate(pipeline).to_list(None)
```

**Слайд 20: Индексы**

Индексы в MongoDB работают так же, как в реляционных БД - ускоряют поиск.

Без индекса MongoDB сканирует всю коллекцию (collection scan). С индексом - только нужные документы.

### Создание индексов

```python
# Простой индекс по одному полю
await collection.create_index("name")

# Составной индекс (по нескольким полям)
await collection.create_index([
    ("age", 1),  # 1 = ascending (по возрастанию)
    ("name", -1)  # -1 = descending (по убыванию)
])

# Уникальный индекс (значения должны быть уникальными)
await collection.create_index("email", unique=True)

# Текстовый индекс для полнотекстового поиска
await collection.create_index([("description", "text")])

# Поиск по текстовому индексу
cursor = collection.find({"$text": {"$search": "python mongodb"}})
```

### Типы индексов

1. **Single Field Index** - по одному полю
2. **Compound Index** - по нескольким полям (порядок важен!)
3. **Multikey Index** - для массивов (автоматически)
4. **Text Index** - для полнотекстового поиска
5. **Geospatial Index** - для геоданных
6. **Hashed Index** - для шардинга

### Когда создавать индексы?

- Поля, по которым часто ищете
- Поля для сортировки
- Поля для JOIN ($lookup)

### Когда НЕ создавать индексы?

- Маленькие коллекции (< 1000 документов)
- Поля, которые часто меняются
- Поля с низкой селективностью (например, пол: M/F)

Индексы ускоряют чтение, но замедляют запись (нужно обновлять индекс).

---

## Часть 5: FastAPI + MongoDB (10 минут)

**Слайд 21: FastAPI + MongoDB - Модели**

Теперь интегрируем MongoDB с FastAPI. Используем Pydantic для валидации данных.

```python
from pydantic import BaseModel, Field, ConfigDict
from typing import Optional

class Student(BaseModel):
    # Конфигурация для работы с MongoDB
    model_config = ConfigDict(
        populate_by_name=True,  # Разрешить использование alias
        arbitrary_types_allowed=True  # Разрешить произвольные типы
    )
    
    # MongoDB использует _id, но в Python удобнее id
    id: Optional[str] = Field(default=None, alias="_id")
    name: str = Field(..., min_length=1, max_length=100)
    age: int = Field(..., ge=0, le=150)
    courses: list[str] = []
    email: Optional[str] = None

# Модель для создания (без id)
class StudentCreate(BaseModel):
    name: str
    age: int
    courses: list[str] = []
    email: Optional[str] = None
```

Важные моменты:
- `alias="_id"` - маппинг MongoDB `_id` на Python `id`
- `populate_by_name=True` - позволяет использовать оба имени
- `model_dump(by_alias=True)` - конвертирует `id` обратно в `_id`

**Слайд 22: FastAPI + MongoDB - Эндпоинты**

Создадим CRUD API для студентов.

```python
from fastapi import FastAPI, HTTPException, status
from motor.motor_asyncio import AsyncIOMotorClient
from bson import ObjectId

app = FastAPI()

# Подключение к MongoDB
client = AsyncIOMotorClient("mongodb://localhost:27017")
db = client.university_db

# Dependency для получения коллекции
def get_collection():
    return db.students

# CREATE - создать студента
@app.post("/students/", response_model=Student, status_code=status.HTTP_201_CREATED)
async def create_student(student: StudentCreate):
    # Конвертируем Pydantic модель в dict
    student_dict = student.model_dump()
    
    # Вставляем в MongoDB
    result = await db.students.insert_one(student_dict)
    
    # Получаем созданный документ
    created_student = await db.students.find_one({"_id": result.inserted_id})
    
    # Конвертируем ObjectId в строку
    created_student["_id"] = str(created_student["_id"])
    
    return created_student

# READ - получить всех студентов
@app.get("/students/", response_model=list[Student])
async def get_students(skip: int = 0, limit: int = 100):
    cursor = db.students.find().skip(skip).limit(limit)
    students = await cursor.to_list(length=limit)
    
    # Конвертируем ObjectId в строку
    for student in students:
        student["_id"] = str(student["_id"])
    
    return students

# READ - получить одного студента по ID
@app.get("/students/{student_id}", response_model=Student)
async def get_student(student_id: str):
    # Проверяем валидность ObjectId
    if not ObjectId.is_valid(student_id):
        raise HTTPException(status_code=400, detail="Invalid student ID")
    
    student = await db.students.find_one({"_id": ObjectId(student_id)})
    
    if student is None:
        raise HTTPException(status_code=404, detail="Student not found")
    
    student["_id"] = str(student["_id"])
    return student

# UPDATE - обновить студента
@app.put("/students/{student_id}", response_model=Student)
async def update_student(student_id: str, student: StudentCreate):
    if not ObjectId.is_valid(student_id):
        raise HTTPException(status_code=400, detail="Invalid student ID")
    
    # Обновляем документ
    result = await db.students.update_one(
        {"_id": ObjectId(student_id)},
        {"$set": student.model_dump()}
    )
    
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Student not found")
    
    # Получаем обновленный документ
    updated_student = await db.students.find_one({"_id": ObjectId(student_id)})
    updated_student["_id"] = str(updated_student["_id"])
    
    return updated_student

# DELETE - удалить студента
@app.delete("/students/{student_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_student(student_id: str):
    if not ObjectId.is_valid(student_id):
        raise HTTPException(status_code=400, detail="Invalid student ID")
    
    result = await db.students.delete_one({"_id": ObjectId(student_id)})
    
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Student not found")
    
    return None
```

### Важные моменты:

1. **ObjectId** - MongoDB использует специальный тип для ID. Нужно конвертировать:
   - Из строки в ObjectId: `ObjectId(student_id)`
   - Из ObjectId в строку: `str(student["_id"])`

2. **Валидация ObjectId** - проверяем `ObjectId.is_valid()` перед использованием

3. **Обработка ошибок** - возвращаем 404 если документ не найден

**Слайд 23: MongoDB - Плюсы и минусы**

Давайте подведем итоги по MongoDB.

### Плюсы:

✅ **Гибкая схема** - можно менять структуру данных без миграций

✅ **Высокая производительность** - быстрая запись и чтение

✅ **Горизонтальное масштабирование** - легко добавлять серверы

✅ **Богатый язык запросов** - агрегации, вложенные документы

✅ **Хорошо подходит для иерархических данных** - JSON-структуры

### Минусы:

❌ **Нет JOIN** - нужно делать несколько запросов или использовать $lookup (медленно)

❌ **Больше памяти** - BSON занимает больше места чем реляционные таблицы

❌ **Нет транзакций** (до версии 4.0) - сложно обеспечить ACID

❌ **Дублирование данных** - часто приходится денормализовать

❌ **Сложность поддержки консистентности** - eventual consistency

### Когда использовать MongoDB?

- Каталоги товаров (разная структура у разных товаров)
- Профили пользователей (гибкая схема)
- CMS (контент с разной структурой)
- Логирование (высокая скорость записи)
- Прототипы (быстрая разработка без миграций)

### Когда НЕ использовать MongoDB?

- Финансовые транзакции (нужны ACID гарантии)
- Сложные связи между данными (много JOIN)
- Строгая схема данных (лучше PostgreSQL)

---

## Часть 6: OpenSearch (25 минут)

**Слайд 24: OpenSearch**

Теперь переходим ко второй NoSQL базе - OpenSearch.

OpenSearch - это **распределенная поисковая система** и **аналитическая платформа**.

Основные фишки:

🔍 **Полнотекстовый поиск** - ищет по словам, с морфологией, опечатками

📊 **Аналитика в реальном времени** - агрегации за миллисекунды

🌐 **RESTful API** - все операции через HTTP

⚡ **Основана на Apache Lucene** - проверенная поисковая библиотека

**Слайд 25: OpenSearch для РФ**

OpenSearch - это форк Elasticsearch 7.10.2 с открытой лицензией Apache 2.0.

Почему OpenSearch, а не Elasticsearch?

✅ **Поддержка AWS** - активно развивается Amazon

✅ **Совместимость с Elasticsearch API** - можно использовать те же библиотеки

✅ **Активное сообщество** - много контрибьюторов

✅ **Рекомендуется для РФ** - нет проблем с лицензированием

✅ **Бесплатная** - полностью open source

Elasticsearch после версии 7.10 перешел на проприетарную лицензию, что создало проблемы. OpenSearch - это community-driven альтернатива.

**Слайд 26: Установка OpenSearch**

Запускаем OpenSearch через Docker:

```bash
docker run -d -p 9200:9200 -p 9600:9600 \
  -e "discovery.type=single-node" \
  -e "DISABLE_SECURITY_PLUGIN=true" \
  opensearchproject/opensearch:2.11.0
```

Параметры:
- `-d` - запуск в фоновом режиме
- `-p 9200:9200` - REST API (HTTP)
- `-p 9600:9600` - Performance Analyzer
- `discovery.type=single-node` - одиночный узел (без кластера)
- `DISABLE_SECURITY_PLUGIN=true` - отключить аутентификацию (только для разработки!)

Проверка:

```bash
curl http://localhost:9200

# Ответ:
{
  "name" : "opensearch",
  "cluster_name" : "docker-cluster",
  "version" : {
    "number" : "2.11.0"
  }
}
```

⚠️ **Важно**: В продакшене ОБЯЗАТЕЛЬНО включайте security plugin и используйте HTTPS!

**Слайд 27: Основные концепции**

OpenSearch имеет свою терминологию:

### Иерархия данных

```
Cluster (кластер)
  └─ Index (индекс) ≈ Database
       └─ Document (документ) ≈ Row
            └─ Field (поле) ≈ Column
```

### Основные понятия

**Index (индекс)** - аналог базы данных или таблицы. Хранит документы одного типа.

**Document (документ)** - JSON-объект с данными. Аналог строки в таблице.

**Field (поле)** - ключ-значение в документе. Аналог колонки.

**Mapping (маппинг)** - схема данных. Определяет типы полей и как их индексировать.

**Shard (шард)** - часть индекса. Индекс разбивается на шарды для распределения по серверам.

**Replica (реплика)** - копия шарда для отказоустойчивости.

### Отличия от MongoDB

| Концепция | MongoDB | OpenSearch |
|-----------|---------|------------|
| База данных | Database | Index |
| Таблица | Collection | Index |
| Строка | Document | Document |
| Схема | Гибкая | Mapping (обязательный) |

**Слайд 28: Подключение Python**

Для работы с OpenSearch используем библиотеку `opensearch-py`:

```bash
pip install opensearch-py
```

Подключение:

```python
from opensearchpy import AsyncOpenSearch

client = AsyncOpenSearch(
    hosts=[{"host": "localhost", "port": 9200}],
    http_auth=("admin", "admin"),  # Логин/пароль (если security включен)
    use_ssl=False,  # Без SSL для разработки
    verify_certs=False,  # Не проверять сертификаты
    ssl_show_warn=False  # Не показывать предупреждения
)

# Проверка подключения
info = await client.info()
print(info["version"]["number"])
```

Для продакшена:

```python
client = AsyncOpenSearch(
    hosts=[{"host": "opensearch.example.com", "port": 9200}],
    http_auth=("username", "password"),
    use_ssl=True,  # HTTPS
    verify_certs=True,  # Проверять сертификаты
    ca_certs="/path/to/ca.crt"  # Путь к CA сертификату
)
```

**Слайд 29: Создание индекса**

Перед добавлением документов нужно создать индекс и определить маппинг (схему).

```python
index_body = {
    "settings": {  # Настройки индекса
        "number_of_shards": 1,  # Количество шардов
        "number_of_replicas": 0  # Количество реплик
    },
    "mappings": {  # Схема данных
        "properties": {
            "title": {"type": "text"},  # Полнотекстовый поиск
            "content": {"type": "text"},
            "author": {"type": "keyword"},  # Точное совпадение
            "created_at": {"type": "date"},
            "views": {"type": "integer"},
            "tags": {"type": "keyword"}  # Массив строк
        }
    }
}

# Создание индекса
await client.indices.create(index="articles", body=index_body)
```

### Типы полей

**text** - для полнотекстового поиска. Анализируется (токенизация, стемминг).

```python
{"type": "text"}
# "Hello World" → ["hello", "world"]
```

**keyword** - для точного совпадения. Хранится как есть.

```python
{"type": "keyword"}
# "Hello World" → "Hello World" (без изменений)
```

**Когда использовать:**
- `text` - для поиска по содержимому (статьи, описания)
- `keyword` - для фильтрации и сортировки (теги, статусы, email)

**Числовые типы:**
- `integer`, `long` - целые числа
- `float`, `double` - дробные числа

**Другие типы:**
- `date` - дата и время
- `boolean` - true/false
- `geo_point` - географические координаты
- `object` - вложенный объект
- `nested` - массив объектов

### Настройки индекса

**number_of_shards** - на сколько частей разбить индекс.
- Для dev: 1
- Для prod: 3-5 (зависит от объема данных)
- Нельзя изменить после создания!

**number_of_replicas** - сколько копий каждого шарда.
- Для dev: 0 (экономим ресурсы)
- Для prod: 1-2 (отказоустойчивость)
- Можно изменить в любой момент

**Слайд 30: Индексация документов**

Добавление документов в OpenSearch называется **индексацией**.

### Добавить один документ

```python
doc = {
    "title": "Введение в NoSQL",
    "content": "NoSQL базы данных предоставляют гибкую схему...",
    "author": "Иван Иванов",
    "created_at": "2025-01-15T10:00:00",
    "views": 100,
    "tags": ["nosql", "mongodb", "opensearch"]
}

# Добавить документ с ID=1
await client.index(index="articles", id="1", body=doc)

# Добавить документ с автоматическим ID
result = await client.index(index="articles", body=doc)
print(result["_id"])  # Сгенерированный ID
```

### Массовая индексация (bulk)

Для добавления множества документов используйте bulk API - это в 10-100 раз быстрее!

```python
from opensearchpy.helpers import async_bulk

# Подготовка данных
actions = [
    {
        "_index": "articles",
        "_id": str(i),
        "_source": {
            "title": f"Статья {i}",
            "content": f"Содержимое статьи {i}",
            "author": "Автор",
            "created_at": "2025-01-15",
            "views": i * 10
        }
    }
    for i in range(1000)
]

# Массовая индексация
success, failed = await async_bulk(client, actions)
print(f"Успешно: {success}, Ошибок: {len(failed)}")
```

### Что происходит при индексации?

1. **Анализ текста** - документ разбивается на токены (слова)
2. **Создание инвертированного индекса** - слово → список документов
3. **Сохранение** - документ становится доступен для поиска (~1 сек задержка)

Пример инвертированного индекса:

```
Документ 1: "NoSQL базы данных"
Документ 2: "Реляционные базы данных"

Инвертированный индекс:
"nosql" → [1]
"базы" → [1, 2]
"данных" → [1, 2]
"реляционные" → [2]
```

Теперь поиск "базы" мгновенно находит документы [1, 2].

---

(Продолжение следует...)

## Часть 7: Поиск в OpenSearch (15 минут)

**Слайд 31: Поиск - Match Query**

Самый простой тип поиска - **match query**. Ищет по словам в тексте.

```python
# Полнотекстовый поиск
query = {
    "query": {
        "match": {
            "content": "NoSQL базы данных"
        }
    }
}

response = await client.search(index="articles", body=query)

# Обработка результатов
hits = response["hits"]["hits"]  # Список найденных документов
total = response["hits"]["total"]["value"]  # Всего найдено

for hit in hits:
    print(f"ID: {hit['_id']}, Score: {hit['_score']}")
    print(f"Title: {hit['_source']['title']}")
    print(f"Content: {hit['_source']['content']}")
    print("---")
```

### Как работает match?

1. Запрос "NoSQL базы данных" разбивается на слова: ["nosql", "базы", "данных"]
2. OpenSearch ищет документы, содержащие ЛЮБОЕ из этих слов
3. Документы ранжируются по релевантности (score)

### Match vs Match Phrase

```python
# match - ищет любое слово (OR)
{"query": {"match": {"content": "NoSQL базы"}}}
# Найдет: "NoSQL системы", "Базы данных", "NoSQL базы"

# match_phrase - ищет точную фразу
{"query": {"match_phrase": {"content": "NoSQL базы"}}}
# Найдет только: "NoSQL базы" (слова рядом в таком порядке)
```

### Score (релевантность)

OpenSearch вычисляет score для каждого документа:
- Чем больше совпадений - тем выше score
- Чем реже слово встречается в индексе - тем выше его вес
- Документы сортируются по score (самые релевантные первые)

**Слайд 32: Поиск - Bool Query**

Bool query - это мощный инструмент для комбинирования условий.

```python
query = {
    "query": {
        "bool": {
            "must": [  # Обязательно (AND)
                {"match": {"content": "NoSQL"}}
            ],
            "filter": [  # Фильтры (не влияют на score)
                {"term": {"author": "Иван Иванов"}},  # Точное совпадение
                {"range": {"views": {"gte": 50}}}  # views >= 50
            ],
            "should": [  # Желательно (OR, повышает score)
                {"match": {"title": "MongoDB"}}
            ],
            "must_not": [  # Исключить (NOT)
                {"term": {"status": "draft"}}
            ]
        }
    }
}

response = await client.search(index="articles", body=query)
```

### Логика работы

**must** - документ ОБЯЗАН соответствовать, увеличивает score

```python
"must": [
    {"match": {"content": "NoSQL"}},
    {"match": {"content": "MongoDB"}}
]
# Документ должен содержать И "NoSQL" И "MongoDB"
```

**filter** - документ ОБЯЗАН соответствовать, НЕ влияет на score (быстрее, кешируется)

```python
"filter": [
    {"term": {"author": "Иван"}},
    {"range": {"views": {"gte": 100}}}
]
# Автор = "Иван" И просмотры >= 100
# Не влияет на релевантность, только фильтрует
```

**should** - необязательно, но если совпадает - повышает score (бонус)

```python
"should": [
    {"match": {"title": "MongoDB"}},
    {"match": {"title": "OpenSearch"}}
]
# Если в заголовке есть "MongoDB" или "OpenSearch" - документ получит бонус к score
```

**must_not** - документ НЕ ДОЛЖЕН соответствовать (исключение)

```python
"must_not": [
    {"term": {"status": "draft"}},
    {"term": {"deleted": true}}
]
# Исключить черновики и удаленные
```

### Пример: Поиск статей

Найти статьи про NoSQL от Ивана с views >= 50, не черновики, приоритет статьям с MongoDB в заголовке:

```python
query = {
    "query": {
        "bool": {
            "must": [
                {"match": {"content": "NoSQL"}}  # Обязательно про NoSQL
            ],
            "filter": [
                {"term": {"author": "Иван Иванов"}},  # От Ивана
                {"range": {"views": {"gte": 50}}}  # >= 50 просмотров
            ],
            "should": [
                {"match": {"title": "MongoDB"}}  # Бонус за MongoDB в заголовке
            ],
            "must_not": [
                {"term": {"status": "draft"}}  # Не черновики
            ]
        }
    }
}
```

**Слайд 33: Поиск - Fuzzy и Wildcard**

OpenSearch умеет искать с опечатками и по шаблонам.

### Fuzzy Search (нечеткий поиск)

Находит слова с опечатками (до 2 символов отличия):

```python
# Ищем "database", но с опечатками
query = {
    "query": {
        "fuzzy": {
            "title": {
                "value": "databse",  # Опечатка: пропущена "a"
                "fuzziness": 2  # Максимум 2 отличия
            }
        }
    }
}
# Найдет: "database", "databases", "databse"
```

Параметр `fuzziness`:
- `0` - точное совпадение
- `1` - 1 символ отличия
- `2` - 2 символа отличия
- `AUTO` - автоматически (рекомендуется)

### Wildcard (поиск по шаблону)

```python
# * = любые символы, ? = один символ
query = {
    "query": {
        "wildcard": {
            "title": "data*"  # Начинается с "data"
        }
    }
}
# Найдет: "database", "data", "datastore", "data science"

query = {
    "query": {
        "wildcard": {
            "title": "no?ql"  # 3-й символ любой
        }
    }
}
# Найдет: "nosql", "noSQL", "no1ql"
```

### Prefix (поиск по началу)

```python
query = {
    "query": {
        "prefix": {
            "title": "no"  # Начинается с "no"
        }
    }
}
# Найдет: "nosql", "node", "notebook"
# Полезно для автодополнения
```

### Regexp (регулярные выражения)

```python
query = {
    "query": {
        "regexp": {
            "title": "no[a-z]+"  # "no" + одна или более букв
        }
    }
}
# Найдет: "nosql", "node", но не "no123"
```

⚠️ **Важно**: wildcard и regexp - медленные запросы! Они сканируют весь индекс. Комбинируйте с filter для ускорения.

**Слайд 34: Агрегации**

Агрегации в OpenSearch - это аналитика в реальном времени.

### Базовый пример

```python
query = {
    "size": 0,  # Не возвращать документы, только агрегации
    "aggs": {
        "authors": {  # Название агрегации
            "terms": {  # Группировка по значениям
                "field": "author",  # Поле для группировки
                "size": 10  # TOP-10 авторов
            }
        }
    }
}

response = await client.search(index="articles", body=query)
buckets = response["aggregations"]["authors"]["buckets"]

for bucket in buckets:
    print(f"Автор: {bucket['key']}, Статей: {bucket['doc_count']}")
```

### Вложенные агрегации

```python
query = {
    "size": 0,
    "aggs": {
        "authors": {
            "terms": {"field": "author"},
            "aggs": {  # Вложенная агрегация
                "avg_views": {
                    "avg": {"field": "views"}  # Средние просмотры для каждого автора
                }
            }
        }
    }
}

response = await client.search(index="articles", body=query)
for bucket in response["aggregations"]["authors"]["buckets"]:
    author = bucket["key"]
    count = bucket["doc_count"]
    avg_views = bucket["avg_views"]["value"]
    print(f"{author}: {count} статей, среднее {avg_views:.1f} просмотров")
```

### Типы агрегаций

**Метрические (вычисления):**

```python
# Статистика по полю (min, max, avg, sum, count)
{"stats": {"field": "views"}}

# Среднее
{"avg": {"field": "views"}}

# Сумма
{"sum": {"field": "views"}}

# Минимум/максимум
{"min": {"field": "views"}}
{"max": {"field": "views"}}

# Количество уникальных значений
{"cardinality": {"field": "author"}}
```

**Bucket агрегации (группировка):**

```python
# Группировка по значениям (TOP-N)
{"terms": {"field": "author", "size": 10}}

# Группировка по диапазонам
{"range": {
    "field": "views",
    "ranges": [
        {"to": 100},  # < 100
        {"from": 100, "to": 1000},  # 100-1000
        {"from": 1000}  # > 1000
    ]
}}

# Гистограмма по дате
{"date_histogram": {
    "field": "created_at",
    "calendar_interval": "month"  # По месяцам
}}
```

### Комплексный пример

```python
query = {
    "size": 0,
    "query": {
        "range": {"created_at": {"gte": "2024-01-01"}}  # Статьи за 2024 год
    },
    "aggs": {
        "by_month": {
            "date_histogram": {
                "field": "created_at",
                "calendar_interval": "month"
            },
            "aggs": {
                "total_views": {"sum": {"field": "views"}},
                "avg_views": {"avg": {"field": "views"}},
                "top_authors": {
                    "terms": {"field": "author", "size": 3}
                }
            }
        }
    }
}
# Получим статистику по месяцам: сумма просмотров, среднее, TOP-3 автора
```

**Слайд 35: Сортировка и пагинация**

### Сортировка

```python
query = {
    "query": {"match_all": {}},  # Все документы
    "sort": [
        {"created_at": {"order": "desc"}},  # Сначала по дате (новые первые)
        {"views": {"order": "desc"}},  # Потом по просмотрам
        "_score"  # Потом по релевантности
    ]
}
```

Важно:
- Сортировка только по `keyword`, `numeric`, `date` полям (не `text`!)
- `order`: `asc` (по возрастанию) или `desc` (по убыванию)
- `_score` - сортировка по релевантности

### Пагинация (from/size)

```python
query = {
    "query": {"match_all": {}},
    "from": 0,  # Пропустить N документов (offset)
    "size": 10  # Вернуть 10 документов (limit)
}

# Страница 1: from=0, size=10
# Страница 2: from=10, size=10
# Страница 3: from=20, size=10
```

⚠️ **Проблема**: `from` > 10000 - медленно! OpenSearch обрабатывает `from + size` документов.

Пример: `from=10000, size=10` → OpenSearch обрабатывает 10010 документов, отбрасывает 10000.

### Search After (для больших данных)

Для пагинации больших объемов используйте `search_after`:

```python
# Первый запрос
query = {
    "query": {"match_all": {}},
    "size": 10,
    "sort": [{"created_at": "desc"}, {"_id": "asc"}]  # Обязательно уникальная сортировка
}

response = await client.search(index="articles", body=query)
hits = response["hits"]["hits"]

# Следующая страница
last_hit = hits[-1]
query["search_after"] = last_hit["sort"]  # Продолжить с последнего документа

response = await client.search(index="articles", body=query)
```

`search_after` быстрее, но нельзя прыгать на произвольную страницу (только вперед).

**Слайд 36: FastAPI + OpenSearch**

Интегрируем OpenSearch с FastAPI.

```python
from fastapi import FastAPI, Query, HTTPException
from opensearchpy import AsyncOpenSearch
from pydantic import BaseModel
from typing import Optional

app = FastAPI()

# Подключение к OpenSearch
client = AsyncOpenSearch(
    hosts=[{"host": "localhost", "port": 9200}],
    use_ssl=False
)

# Модель для статьи
class Article(BaseModel):
    title: str
    content: str
    author: str
    tags: list[str] = []

# Модель для результатов поиска
class SearchResult(BaseModel):
    id: str
    score: float
    title: str
    content: str
    author: str

# Поиск статей
@app.get("/search", response_model=dict)
async def search_articles(
    q: str = Query(..., description="Поисковый запрос"),
    author: Optional[str] = Query(None, description="Фильтр по автору"),
    page: int = Query(1, ge=1, description="Номер страницы"),
    size: int = Query(10, ge=1, le=100, description="Размер страницы")
):
    # Построение запроса
    query = {
        "query": {
            "bool": {
                "must": [
                    {"match": {"content": q}}  # Поиск по содержимому
                ]
            }
        },
        "from": (page - 1) * size,
        "size": size,
        "sort": ["_score", {"created_at": "desc"}]  # Сортировка
    }
    
    # Фильтр по автору (если указан)
    if author:
        query["query"]["bool"]["filter"] = [
            {"term": {"author": author}}
        ]
    
    # Выполнение поиска
    try:
        response = await client.search(index="articles", body=query)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")
    
    # Обработка результатов
    hits = response["hits"]["hits"]
    total = response["hits"]["total"]["value"]
    
    results = [
        SearchResult(
            id=hit["_id"],
            score=hit["_score"],
            title=hit["_source"]["title"],
            content=hit["_source"]["content"],
            author=hit["_source"]["author"]
        )
        for hit in hits
    ]
    
    return {
        "total": total,
        "page": page,
        "size": size,
        "pages": (total + size - 1) // size,  # Округление вверх
        "results": results
    }

# Создать статью
@app.post("/articles", status_code=201)
async def create_article(article: Article):
    doc = article.model_dump()
    doc["created_at"] = "2025-01-15T10:00:00"  # В реальности: datetime.now()
    doc["views"] = 0
    
    result = await client.index(index="articles", body=doc)
    
    return {"id": result["_id"], "message": "Article created"}

# Автодополнение
@app.get("/autocomplete")
async def autocomplete(q: str = Query(..., min_length=2)):
    query = {
        "query": {
            "prefix": {
                "title": q.lower()
            }
        },
        "size": 5,
        "_source": ["title"]
    }
    
    response = await client.search(index="articles", body=query)
    suggestions = [hit["_source"]["title"] for hit in response["hits"]["hits"]]
    
    return {"suggestions": suggestions}
```

**Слайд 37: Анализаторы для русского**

Для качественного поиска по русскому тексту нужен специальный анализатор.

```python
index_body = {
    "settings": {
        "analysis": {
            "analyzer": {
                "russian_analyzer": {
                    "type": "custom",
                    "tokenizer": "standard",  # Разбивка на слова
                    "filter": [
                        "lowercase",  # Приведение к нижнему регистру
                        "russian_stop",  # Удаление стоп-слов (и, в, на, с...)
                        "russian_stemmer"  # Стемминг (бежать→беж, бежал→беж)
                    ]
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "title": {
                "type": "text",
                "analyzer": "russian_analyzer"  # Используем наш анализатор
            },
            "content": {
                "type": "text",
                "analyzer": "russian_analyzer"
            }
        }
    }
}

await client.indices.create(index="articles", body=index_body)
```

### Процесс анализа текста

Текст: "Я бежал по улице"

1. **tokenizer (standard)**: ["Я", "бежал", "по", "улице"]
2. **lowercase**: ["я", "бежал", "по", "улице"]
3. **russian_stop**: ["бежал", "улице"] (удалены "я", "по")
4. **russian_stemmer**: ["беж", "улиц"] (корни слов)

Теперь поиск "бежит", "бежал", "бегу" найдут одинаковые документы (все → "беж")!

### Тестирование анализатора

```python
# Проверить, как анализируется текст
response = await client.indices.analyze(
    index="articles",
    body={
        "analyzer": "russian_analyzer",
        "text": "Я бежал по улице"
    }
)

tokens = [token["token"] for token in response["tokens"]]
print(tokens)  # ["беж", "улиц"]
```

---

## Часть 8: Сравнение и итоги (5 минут)

**Слайд 38: OpenSearch - Плюсы и минусы**

### Плюсы:

✅ **Мощный полнотекстовый поиск** - fuzzy, wildcard, regexp, морфология

✅ **Аналитика в реальном времени** - агрегации за миллисекунды

✅ **Богатые агрегации** - terms, stats, histogram, вложенные

✅ **Горизонтальное масштабирование** - легко добавлять узлы

✅ **Подсветка результатов** - highlight найденных слов

### Минусы:

❌ **Высокое потребление ресурсов** - много RAM и CPU

❌ **Сложность настройки** - маппинги, анализаторы, шарды

❌ **Near real-time** - задержка ~1 сек при индексации

❌ **Не подходит для транзакций** - eventual consistency

❌ **Дублирование данных** - обычно используется как вторичный индекс

**Слайд 39: MongoDB vs OpenSearch**

| Критерий | MongoDB | OpenSearch |
|----------|---------|------------|
| **Назначение** | Общего назначения (CRUD) | Поиск и аналитика |
| **Схема** | Гибкая (schemaless) | Требует маппинга |
| **Поиск** | Базовый ($text) | Полнотекстовый (Lucene) |
| **Транзакции** | Есть (ACID с 4.0) | Нет |
| **Скорость записи** | Высокая | Средняя (индексация) |
| **Скорость чтения** | Высокая | Очень высокая (поиск) |
| **Ресурсы** | Умеренные | Высокие (RAM) |
| **Агрегации** | Хорошие | Отличные |
| **Масштабирование** | Шардинг | Шардинг + реплики |

**Слайд 40: Когда использовать MongoDB?**

📦 **Основное хранилище данных** - MongoDB как primary database

🔄 **Гибкая схема данных** - структура часто меняется

⚡ **Высокая скорость записи** - логи, события, IoT

🌳 **Иерархические данные** - JSON-структуры, вложенные объекты

**Примеры:**
- Каталог товаров (разные характеристики)
- Профили пользователей
- CMS (контент с разной структурой)
- IoT данные (сенсоры, метрики)

**Слайд 41: Когда использовать OpenSearch?**

🔍 **Полнотекстовый поиск** - поиск по сайту, документам

📝 **Логирование и мониторинг** - ELK stack (Elasticsearch/OpenSearch + Logstash + Kibana)

📊 **Аналитика в реальном времени** - дашборды, метрики

📄 **Поиск по документам** - PDF, Word, текстовые файлы

**Примеры:**
- Поиск по интернет-магазину
- Мониторинг логов приложений
- Аналитика пользовательского поведения
- Поиск по базе знаний

**Слайд 42: Гибридный подход**

Часто используют MongoDB + OpenSearch вместе:

```
┌─────────────┐
│   FastAPI   │
└──────┬──────┘
       │
   ┌───┴────┐
   │        │
┌──▼──┐  ┌──▼────────┐
│MongoDB│  │OpenSearch│
└─────┘  └───────────┘
Primary     Search
Storage     Index
```

### Паттерн работы:

1. **Данные хранятся в MongoDB** (primary storage)
2. **При изменении → синхронизация в OpenSearch** (search index)
3. **Поиск → OpenSearch** (быстрый полнотекстовый поиск)
4. **Полные данные → MongoDB** (получение по ID)

### Пример кода:

```python
# Создание статьи
@app.post("/articles")
async def create_article(article: Article):
    # 1. Сохранить в MongoDB
    result = await mongo_db.articles.insert_one(article.model_dump())
    article_id = str(result.inserted_id)
    
    # 2. Индексировать в OpenSearch
    await opensearch_client.index(
        index="articles",
        id=article_id,
        body={
            "title": article.title,
            "content": article.content,
            "author": article.author
        }
    )
    
    return {"id": article_id}

# Поиск
@app.get("/search")
async def search(q: str):
    # 1. Поиск в OpenSearch
    response = await opensearch_client.search(
        index="articles",
        body={"query": {"match": {"content": q}}}
    )
    
    # 2. Получить ID найденных документов
    ids = [hit["_id"] for hit in response["hits"]["hits"]]
    
    # 3. Получить полные данные из MongoDB
    articles = await mongo_db.articles.find(
        {"_id": {"$in": [ObjectId(id) for id in ids]}}
    ).to_list(length=100)
    
    return {"results": articles}
```

**Слайд 43: Итоги**

### Ключевые выводы:

✅ **NoSQL решает проблемы масштабирования** - горизонтальное масштабирование

✅ **MongoDB - для гибкого хранения** - документы, иерархии, быстрая запись

✅ **OpenSearch - для поиска и аналитики** - полнотекстовый поиск, агрегации

✅ **Выбор зависит от задачи** - нет универсального решения

✅ **Можно комбинировать** - MongoDB + OpenSearch = мощная связка

### Что изучили:

- Типы NoSQL баз данных
- MongoDB: CRUD, агрегации, индексы
- OpenSearch: поиск, агрегации, анализаторы
- Интеграция с FastAPI
- Когда использовать каждую технологию

### Ресурсы для изучения:

**MongoDB:**
- MongoDB University (бесплатные курсы)
- Документация: docs.mongodb.com
- Motor: motor.readthedocs.io

**OpenSearch:**
- OpenSearch Documentation: opensearch.org/docs
- opensearch-py: github.com/opensearch-project/opensearch-py
- Kibana/OpenSearch Dashboards для визуализации

### Домашнее задание (опционально):

1. Создать FastAPI приложение с MongoDB для блога
2. Добавить полнотекстовый поиск через OpenSearch
3. Реализовать агрегации (статистика по авторам, тегам)
4. Добавить пагинацию и сортировку

---

## Заключение

Ребят, сегодня мы разобрали две мощные NoSQL базы данных. Главное - понять, что NoSQL это не замена SQL, а дополнение. Каждая технология решает свои задачи.

**MongoDB** - когда нужна гибкость и скорость. **OpenSearch** - когда нужен поиск и аналитика.

В реальных проектах часто используют комбинацию: PostgreSQL для транзакций, MongoDB для гибких данных, OpenSearch для поиска, Redis для кеша.

Вопросы?

---

**Конец лекции**

Время: ~90 минут
- Введение в NoSQL: 15 мин
- MongoDB: 35 мин
- OpenSearch: 35 мин
- Сравнение и итоги: 5 мин
